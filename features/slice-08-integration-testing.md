# Slice 08 - Integration Testing & E2E Pipeline

**Status:** Completed
**Dependencies:** Slices 01-07
**Test Coverage Target:** â‰¥80%
**Delivery Date:** 2025-11-11

---

## Overview

Complete end-to-end pipeline testing and integration testing across all slices. This slice focuses on ensuring all components work together correctly, fixing test isolation issues, and creating comprehensive integration tests that validate the entire weekly news aggregation workflow.

## Goals

1. **Fix Test Isolation Issues:** Resolve mock cleanup and test interference problems
2. **Integration Tests:** Create tests that validate interactions between multiple components
3. **E2E Pipeline Tests:** Test the complete workflow from RSS fetching to LinkedIn publishing
4. **Test Infrastructure:** Improve test fixtures, mocks, and test data management
5. **CI/CD Validation:** Ensure all tests pass reliably in CI environment

## Current Issues (Discovered During Slice 08)

### Test Isolation Problems
- When running all unit tests together (`pytest -m unit`), composer tests interfere with fetcher tests
- Individual test files pass when run separately
- Issue: Mock cleanup not working properly across test modules
- Root cause: TBD (investigate pytest-mock, fixture scope, or autouse fixtures)

### Missing Dependencies
- `beautifulsoup4` was missing from requirements.txt (added in this slice)

## Scope

### 1. Test Isolation Fixes

**Priority:** High
**Files to Modify:**
- `src/tests/conftest.py` - Review and fix fixture scopes
- `src/tests/unit/test_*.py` - Ensure proper mock cleanup
- `pytest.ini` - Review test configuration

**Tasks:**
- [ ] Investigate why composer test mocks persist into fetcher tests
- [ ] Add proper teardown for all patched mocks
- [ ] Consider using pytest-mock's `mocker` fixture instead of unittest.mock
- [ ] Add test isolation verification in CI

### 2. Integration Tests

**Priority:** High
**New Files:**
- `src/tests/integration/test_fetch_summarize_pipeline.py`
- `src/tests/integration/test_compose_publish_pipeline.py`
- `src/tests/integration/test_scheduler_integration.py`
- `src/tests/integration/test_source_discovery_integration.py`
- `src/tests/integration/test_observability_integration.py`

**Test Scenarios:**

#### A. Fetch â†’ Summarize Pipeline
```python
def test_fetch_and_summarize_real_articles():
    """
    Given: Real RSS feeds (mocked for determinism)
    When: Articles are fetched and then summarized
    Then: Summaries are generated with correct metadata
    """
```

#### B. Fetch â†’ Summarize â†’ Compose Pipeline
```python
def test_full_content_pipeline():
    """
    Given: Real RSS feeds
    When: Complete pipeline runs (fetch â†’ summarize â†’ compose)
    Then: LinkedIn-ready post is generated with correct format
    """
```

#### C. Scheduler â†’ Pipeline â†’ Publisher
```python
def test_scheduled_pipeline_execution():
    """
    Given: Configured scheduler
    When: Preview job triggers
    Then: Post is drafted and saved locally
    """
```

#### D. Source Discovery Integration
```python
def test_source_discovery_adds_approved_sources():
    """
    Given: Discovery agent finds new sources
    When: Sources are evaluated and approved
    Then: They appear in next week's feed fetching
    """
```

#### E. Observability Integration
```python
def test_metrics_collected_during_pipeline():
    """
    Given: Pipeline runs with observability enabled
    When: Articles are fetched, summarized, and published
    Then: All metrics are recorded correctly
    """
```

### 3. E2E Pipeline Tests

**Priority:** High
**New Files:**
- `src/tests/e2e/test_full_weekly_workflow.py`
- `src/tests/e2e/test_error_recovery.py`

**Test Scenarios:**

#### A. Golden Path - Full Week Workflow
```python
def test_complete_weekly_cycle():
    """
    Given: It's Thursday 18:00
    When: Preview job runs
    Then: Draft post is created

    Given: Draft is approved
    And: It's Friday 10:00
    When: Publish job runs
    Then: Post is published to LinkedIn
    And: Metrics are recorded
    And: Next week's sources are discovered
    """
```

#### B. Error Recovery
```python
def test_pipeline_handles_api_failures():
    """
    Given: Claude API is rate limited
    When: Summarization fails
    Then: Job retries with backoff
    And: Falls back to Ollama if available
    And: Alert is triggered
    """
```

#### C. Data Consistency
```python
def test_idempotency_prevents_duplicate_posts():
    """
    Given: A post for week 2025.W45 already published
    When: Publish job runs again for same week
    Then: No duplicate post is created
    And: Warning is logged
    """
```

### 4. Test Infrastructure Improvements

**Priority:** Medium
**Files to Modify:**
- `src/tests/conftest.py` - Enhanced fixtures
- `src/tests/helpers/` - New test utilities directory

**Improvements:**
- [ ] Create deterministic RSS feed fixtures
- [ ] Add database fixture for SQLite testing
- [ ] Create LinkedIn API mock server
- [ ] Add time travel utilities for scheduler testing
- [ ] Create assertion helpers for complex objects

### 5. CI/CD Integration

**Priority:** Medium
**New Files:**
- `.github/workflows/test.yml` - Comprehensive test workflow

**Configuration:**
```yaml
name: Test Suite
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run unit tests
        run: pytest -m unit --cov=src --cov-report=xml
      - name: Run integration tests
        run: pytest -m integration
      - name: Run E2E tests
        run: pytest -m e2e
      - name: Upload coverage
        uses: codecov/codecov-action@v3
```

## Test Coverage Goals

| Component | Current | Target | Status |
|-----------|---------|--------|--------|
| Fetcher | 90% | 90% | âœ… |
| Summarizer | 100% | 90% | âœ… |
| Composer | 90% | 90% | âœ… |
| Scheduler | 96% | 90% | âœ… |
| Publisher | High | 90% | âœ… |
| Observability | High | 90% | âœ… |
| Source Discovery | 89% | 80% | âœ… |
| **Integration** | **0%** | **â‰¥80%** | ðŸ”„ |
| **E2E** | **~10%** | **â‰¥70%** | ðŸ”„ |

## Acceptance Criteria

### Must Have
- [ ] All unit tests pass in isolation AND when run together
- [ ] At least 15 integration tests covering key workflows
- [ ] At least 5 E2E tests covering golden paths and error cases
- [ ] All tests are deterministic (no flaky tests)
- [ ] Test execution time < 2 minutes for full suite
- [ ] Code coverage â‰¥ 80% overall
- [ ] CI pipeline runs all tests successfully

### Should Have
- [ ] Test execution time < 30 seconds for unit tests only
- [ ] Integration tests use realistic data
- [ ] E2E tests include timing/performance assertions
- [ ] Test documentation includes failure scenarios
- [ ] Parallel test execution configured

### Nice to Have
- [ ] Visual test reports (HTML coverage)
- [ ] Performance benchmarks for each pipeline stage
- [ ] Mutation testing for critical paths
- [ ] Contract testing for API endpoints

## Non-Functional Requirements

### Performance
- Unit tests: < 1s each
- Integration tests: < 5s each
- E2E tests: < 30s each
- Full suite: < 2 minutes

### Reliability
- Zero flaky tests (all tests pass 100/100 runs)
- Deterministic test data
- Proper cleanup after each test

### Maintainability
- Clear test names following Given/When/Then
- DRY principle for test fixtures
- Good error messages on failure
- Test documentation

## Implementation Plan

### Phase 1: Fix Test Isolation (Day 1)
1. Investigate composer/fetcher test interference
2. Fix mock cleanup issues
3. Validate all unit tests pass together
4. Add test isolation checks to CI

### Phase 2: Integration Tests (Day 2)
1. Create integration test structure
2. Implement fetchâ†’summarize tests
3. Implement composeâ†’publish tests
4. Implement scheduler integration tests
5. Implement source discovery integration tests
6. Implement observability integration tests

### Phase 3: E2E Tests (Day 3)
1. Create E2E test fixtures
2. Implement golden path test
3. Implement error recovery tests
4. Implement idempotency tests
5. Add timing/performance assertions

### Phase 4: Test Infrastructure (Day 4)
1. Enhanced test fixtures
2. Test helpers and utilities
3. Assertion helpers
4. Documentation

### Phase 5: CI/CD (Day 5)
1. Create GitHub Actions workflow
2. Configure parallel test execution
3. Add coverage reporting
4. Validate in CI environment

## Out of Scope

- Performance/load testing
- Security testing (separate slice)
- UI/Frontend testing (no UI yet)
- Deployment testing

## Dependencies

### Technical
- pytest==7.4.3
- pytest-cov==4.1.0
- pytest-asyncio==0.21.1
- pytest-mock==3.12.0
- pytest-timeout (new)
- responses (new - for HTTP mocking)

### External
- SQLite database for testing
- Mock RSS feeds
- Mock LinkedIn API

## Risks & Mitigation

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| Test isolation issues hard to fix | High | Medium | Use pytest-mock, review fixture scopes |
| Flaky E2E tests | High | Medium | Use deterministic data, mock time |
| Long test execution times | Medium | Medium | Parallelize tests, optimize fixtures |
| Mock complexity | Medium | Low | Use recorded responses, simplify mocks |

## Success Metrics

- âœ… All tests pass reliably (100/100 runs)
- âœ… Overall code coverage â‰¥ 80%
- âœ… Integration test coverage â‰¥ 80%
- âœ… E2E test coverage â‰¥ 70%
- âœ… Test suite execution < 2 minutes
- âœ… Zero open test-related issues
- âœ… CI pipeline green

## References

- [Testing Strategy](/src/tests/strategy.md)
- [pytest Documentation](https://docs.pytest.org/)
- [Test-Driven Development Best Practices](https://martinfowler.com/bliki/TestDrivenDevelopment.html)

---

**Created:** 2025-11-11
**Last Updated:** 2025-11-11
**Author:** Claude Code
